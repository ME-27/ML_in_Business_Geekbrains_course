{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42e70677",
   "metadata": {},
   "source": [
    "# Pipeline Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21aa818",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb7a83fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d68a3f3",
   "metadata": {},
   "source": [
    "### loading dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ba57195",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df = load_iris(as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6990ebfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(iris_df.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12c8644c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                  5.1               3.5                1.4               0.2\n",
       "1                  4.9               3.0                1.4               0.2\n",
       "2                  4.7               3.2                1.3               0.2\n",
       "3                  4.6               3.1                1.5               0.2\n",
       "4                  5.0               3.6                1.4               0.2\n",
       "..                 ...               ...                ...               ...\n",
       "145                6.7               3.0                5.2               2.3\n",
       "146                6.3               2.5                5.0               1.9\n",
       "147                6.5               3.0                5.2               2.0\n",
       "148                6.2               3.4                5.4               2.3\n",
       "149                5.9               3.0                5.1               1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a89a303",
   "metadata": {},
   "source": [
    "### train test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "834b9f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris_df.data, iris_df.target, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0ec608",
   "metadata": {},
   "source": [
    "### forming the pipeline:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cc7874",
   "metadata": {},
   "source": [
    "sequentially is applied the list of transforms ('scalar', 'pca') and the final estimator ('lr_classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab1a795b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_lr = Pipeline([\n",
    "    ('scalar', StandardScaler()),\n",
    "    ('pca', PCA(n_components=2)),\n",
    "    ('lr_classifier', LogisticRegression(random_state=0))], verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c535b5e5",
   "metadata": {},
   "source": [
    "### fitting the model with train dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3802c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 3) Processing scalar, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 3) Processing pca, total=   0.1s\n",
      "[Pipeline] ..... (step 3 of 3) Processing lr_classifier, total=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scalar', StandardScaler()), ('pca', PCA(n_components=2)),\n",
       "                ('lr_classifier', LogisticRegression(random_state=0))],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b42ea8",
   "metadata": {},
   "source": [
    "### predicting the labels on test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "540075d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 2, 0, 2, 0, 2, 2, 1, 2, 1, 1, 2, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 2, 0, 0, 1, 1, 0, 2, 1, 0, 1, 2, 1, 0, 2, 1, 1, 2, 0, 2, 0,\n",
       "       0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted = pipeline_lr.predict(X_test)\n",
    "y_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd441cba",
   "metadata": {},
   "source": [
    "### let's evaluate the accuracy of our predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a052cfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce01f03e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8666666666666667"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true=y_test, y_pred=y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b571f6",
   "metadata": {},
   "source": [
    "### the same can be done with .score method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c73f194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8666666666666667"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063ff3fe",
   "metadata": {},
   "source": [
    "### if probabilities are required:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4e552f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.71391047e-04, 2.25691282e-01, 7.73737327e-01],\n",
       "       [9.07005837e-03, 7.99234760e-01, 1.91695182e-01],\n",
       "       [9.95432635e-01, 4.56703504e-03, 3.30225956e-07],\n",
       "       [1.70793933e-05, 2.98519860e-02, 9.70130935e-01],\n",
       "       [9.75084659e-01, 2.49123389e-02, 3.00255799e-06],\n",
       "       [1.95994249e-04, 8.83237178e-02, 9.11480288e-01],\n",
       "       [9.80767896e-01, 1.92300790e-02, 2.02526315e-06],\n",
       "       [6.67505151e-03, 4.88820889e-01, 5.04504060e-01],\n",
       "       [2.06817723e-03, 3.62669049e-01, 6.35262774e-01],\n",
       "       [2.55670606e-02, 8.08133529e-01, 1.66299410e-01],\n",
       "       [1.58955598e-03, 3.93389407e-01, 6.05021037e-01],\n",
       "       [2.11273201e-02, 6.80066876e-01, 2.98805804e-01],\n",
       "       [1.59451657e-02, 7.45674877e-01, 2.38379958e-01],\n",
       "       [3.91022037e-03, 4.79549225e-01, 5.16540555e-01],\n",
       "       [1.37490141e-02, 6.97185910e-01, 2.89065076e-01],\n",
       "       [9.90255511e-01, 9.74395514e-03, 5.33528196e-07],\n",
       "       [1.59065474e-02, 7.24572325e-01, 2.59521127e-01],\n",
       "       [2.85595743e-02, 8.67483708e-01, 1.03956717e-01],\n",
       "       [9.36250454e-01, 6.37379648e-02, 1.15807646e-05],\n",
       "       [9.87627042e-01, 1.23712767e-02, 1.68155315e-06],\n",
       "       [4.20396268e-03, 5.30338330e-01, 4.65457707e-01],\n",
       "       [3.99424561e-02, 8.31295759e-01, 1.28761785e-01],\n",
       "       [9.73133902e-01, 2.68627574e-02, 3.34089931e-06],\n",
       "       [9.56346893e-01, 4.36492874e-02, 3.81975642e-06],\n",
       "       [2.36925658e-03, 4.05677680e-01, 5.91953063e-01],\n",
       "       [9.94192128e-01, 5.80770924e-03, 1.62416264e-07],\n",
       "       [9.81676143e-01, 1.83207987e-02, 3.05859947e-06],\n",
       "       [2.22114063e-02, 7.66895652e-01, 2.10892942e-01],\n",
       "       [8.39224909e-02, 8.98523765e-01, 1.75537439e-02],\n",
       "       [9.61633443e-01, 3.83588478e-02, 7.70921955e-06],\n",
       "       [1.73596226e-03, 2.90175352e-01, 7.08088686e-01],\n",
       "       [5.26599201e-02, 8.53260098e-01, 9.40799818e-02],\n",
       "       [9.75856809e-01, 2.41397032e-02, 3.48815826e-06],\n",
       "       [5.38067195e-03, 5.01343376e-01, 4.93275952e-01],\n",
       "       [1.04202082e-04, 9.13315123e-02, 9.08564286e-01],\n",
       "       [5.91651978e-02, 8.88682126e-01, 5.21526765e-02],\n",
       "       [9.72762750e-01, 2.72287590e-02, 8.49082047e-06],\n",
       "       [3.08154672e-03, 4.84401718e-01, 5.12516735e-01],\n",
       "       [3.41056995e-02, 8.08133428e-01, 1.57760873e-01],\n",
       "       [2.68478846e-02, 8.55408656e-01, 1.17743460e-01],\n",
       "       [1.36901348e-04, 8.64105355e-02, 9.13452563e-01],\n",
       "       [9.74448482e-01, 2.55494092e-02, 2.10894426e-06],\n",
       "       [1.46512174e-04, 8.18886416e-02, 9.17964846e-01],\n",
       "       [9.58530236e-01, 4.14589577e-02, 1.08066239e-05],\n",
       "       [9.82263586e-01, 1.77337922e-02, 2.62195326e-06]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_lr.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc85f3b",
   "metadata": {},
   "source": [
    "### let's create pipelines with different classifiers and establish which one is better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e823e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Test Accuracy: 0.87\n",
      "Decision Tree Test Accuracy: 0.91\n",
      "RandomForest Test Accuracy: 0.91\n",
      "\n",
      "Classifier with best accuracy: Decision Tree\n"
     ]
    }
   ],
   "source": [
    "# linear regression pipeline\n",
    "pipeline_lr = Pipeline([('scalar1',StandardScaler()),\n",
    "                        ('pca1',PCA(n_components=2)),\n",
    "                        ('lr_classifier', LogisticRegression(random_state=0))])\n",
    "\n",
    "# decision tree pipeline\n",
    "pipeline_dt = Pipeline([('scalar2',StandardScaler()),\n",
    "                        ('pca2',PCA(n_components=2)),\n",
    "                        ('dt_classifier', DecisionTreeClassifier())])\n",
    "\n",
    "# random forest pipeline\n",
    "pipeline_rf = Pipeline([('scalar3',StandardScaler()),\n",
    "                        ('pca3',PCA(n_components=2)),\n",
    "                        ('rf_classifier', RandomForestClassifier())])\n",
    "\n",
    "# let's make the list of pipelines\n",
    "pipelines = [pipeline_lr, pipeline_dt, pipeline_rf]\n",
    "\n",
    "# dictionary of pipelines and classifier types for ease of reference\n",
    "pipe_dict = {0: 'Logistic Regression', 1: 'Decision Tree', 2: 'RandomForest'}\n",
    "\n",
    "# fit the pipelines\n",
    "for pipe in pipelines:\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "# establishing accuracy of each pipeline/model:\n",
    "for i, model in enumerate(pipelines):\n",
    "    print(f'{pipe_dict[i]} Test Accuracy: {round(model.score(X_test, y_test), 2)}')\n",
    "\n",
    "# establishing pipeline/model with best accuracy:\n",
    "best_accuracy = 0.0\n",
    "best_classifier = 0\n",
    "best_pipeline = \"\"\n",
    "for i, model in enumerate(pipelines):\n",
    "    if model.score(X_test, y_test) > best_accuracy:\n",
    "        best_accuracy = model.score(X_test, y_test)\n",
    "        best_pipeline = model\n",
    "        best_classifier = i\n",
    "print(f'\\nClassifier with best accuracy: {pipe_dict[best_classifier]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7714249",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8134fdfe",
   "metadata": {},
   "source": [
    "# Pipelines Perform Hyperparameter Tuning Using Grid SearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "463c3299",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc1facdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fross\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.95238095        nan 0.94285714        nan 0.94285714        nan\n",
      " 0.96190476        nan 0.97142857        nan 0.96190476        nan\n",
      " 0.96190476        nan 0.95238095        nan 0.95238095        nan\n",
      " 0.95238095        nan 0.95238095 0.98095238 0.98095238 0.94285714\n",
      " 0.94285714 0.98095238 0.98095238 0.97142857 0.94285714 0.98095238\n",
      " 0.98095238 0.97142857 0.96190476 0.98095238 0.98095238 0.98095238\n",
      " 0.97142857 0.98095238 0.98095238 0.98095238 0.96190476 0.98095238\n",
      " 0.98095238 0.97142857 0.96190476 0.98095238 0.98095238 0.97142857\n",
      " 0.96190476 0.98095238 0.98095238 0.97142857 0.96190476 0.98095238\n",
      " 0.98095238 0.97142857 0.96190476 0.98095238 0.98095238 0.97142857\n",
      " 0.8952381  0.91428571 0.93333333 0.95238095 0.91428571 0.92380952\n",
      " 0.88571429 0.9047619  0.93333333 0.8952381  0.9047619  0.91428571\n",
      " 0.8952381  0.91428571 0.93333333 0.37142857 0.37142857 0.37142857\n",
      " 0.94285714 0.94285714 0.94285714 0.93333333 0.95238095 0.94285714\n",
      " 0.94285714 0.94285714 0.94285714 0.93333333 0.94285714 0.94285714\n",
      " 0.95238095 0.95238095 0.95238095 0.36190476 0.37142857 0.37142857\n",
      " 0.92380952 0.94285714 0.94285714 0.94285714 0.94285714 0.94285714\n",
      " 0.94285714 0.95238095 0.94285714 0.95238095 0.94285714 0.94285714\n",
      " 0.93333333 0.93333333 0.95238095 0.36190476 0.37142857 0.37142857\n",
      " 0.83809524 0.8952381  0.91428571 0.88571429 0.91428571 0.92380952\n",
      " 0.77142857 0.91428571 0.92380952 0.85714286 0.91428571 0.93333333\n",
      " 0.92380952 0.92380952 0.93333333 0.37142857 0.37142857 0.37142857\n",
      " 0.93333333 0.94285714 0.94285714 0.95238095 0.94285714 0.94285714\n",
      " 0.92380952 0.94285714 0.94285714 0.95238095 0.94285714 0.94285714\n",
      " 0.92380952 0.94285714 0.93333333 0.37142857 0.37142857 0.37142857\n",
      " 0.94285714 0.94285714 0.94285714 0.93333333 0.93333333 0.94285714\n",
      " 0.93333333 0.94285714 0.94285714 0.93333333 0.93333333 0.94285714\n",
      " 0.92380952 0.93333333 0.94285714 0.37142857 0.37142857 0.37142857\n",
      " 0.84761905 0.92380952 0.93333333 0.81904762 0.92380952 0.91428571\n",
      " 0.87619048 0.93333333 0.91428571 0.8        0.9047619  0.93333333\n",
      " 0.93333333 0.94285714 0.93333333 0.37142857 0.37142857 0.37142857\n",
      " 0.93333333 0.93333333 0.94285714 0.94285714 0.94285714 0.94285714\n",
      " 0.95238095 0.95238095 0.94285714 0.93333333 0.94285714 0.94285714\n",
      " 0.95238095 0.95238095 0.94285714 0.37142857 0.37142857 0.37142857\n",
      " 0.94285714 0.94285714 0.94285714 0.95238095 0.93333333 0.94285714\n",
      " 0.93333333 0.94285714 0.94285714 0.93333333 0.95238095 0.94285714\n",
      " 0.94285714 0.94285714 0.96190476 0.37142857 0.37142857 0.37142857\n",
      " 0.88571429 0.87619048 0.91428571 0.91428571 0.92380952 0.92380952\n",
      " 0.83809524 0.93333333 0.93333333 0.8952381  0.91428571 0.93333333\n",
      " 0.84761905 0.93333333 0.93333333 0.37142857 0.37142857 0.37142857\n",
      " 0.96190476 0.94285714 0.94285714 0.94285714 0.95238095 0.94285714\n",
      " 0.93333333 0.94285714 0.94285714 0.94285714 0.95238095 0.94285714\n",
      " 0.94285714 0.94285714 0.94285714 0.37142857 0.37142857 0.37142857\n",
      " 0.93333333 0.94285714 0.94285714 0.96190476 0.95238095 0.94285714\n",
      " 0.95238095 0.94285714 0.94285714 0.93333333 0.94285714 0.94285714\n",
      " 0.95238095 0.94285714 0.95238095 0.37142857 0.37142857 0.37142857\n",
      " 0.8        0.92380952 0.93333333 0.88571429 0.94285714 0.92380952\n",
      " 0.94285714 0.95238095 0.91428571 0.84761905 0.8952381  0.93333333\n",
      " 0.86666667 0.93333333 0.93333333 0.37142857 0.37142857 0.37142857\n",
      " 0.94285714 0.94285714 0.94285714 0.94285714 0.95238095 0.94285714\n",
      " 0.94285714 0.93333333 0.94285714 0.93333333 0.94285714 0.94285714\n",
      " 0.92380952 0.94285714 0.95238095 0.37142857 0.37142857 0.37142857\n",
      " 0.94285714 0.94285714 0.94285714 0.96190476 0.94285714 0.94285714\n",
      " 0.95238095 0.95238095 0.94285714 0.9047619  0.94285714 0.94285714\n",
      " 0.93333333 0.94285714 0.94285714 0.35238095 0.37142857 0.37142857\n",
      " 0.88571429 0.94285714 0.93333333 0.85714286 0.92380952 0.9047619\n",
      " 0.82857143 0.92380952 0.93333333 0.88571429 0.93333333 0.92380952\n",
      " 0.88571429 0.95238095 0.93333333 0.37142857 0.37142857 0.37142857\n",
      " 0.92380952 0.94285714 0.94285714 0.97142857 0.95238095 0.94285714\n",
      " 0.93333333 0.94285714 0.94285714 0.93333333 0.94285714 0.95238095\n",
      " 0.94285714 0.95238095 0.94285714 0.37142857 0.37142857 0.37142857\n",
      " 0.93333333 0.94285714 0.94285714 0.95238095 0.93333333 0.94285714\n",
      " 0.93333333 0.94285714 0.94285714 0.93333333 0.95238095 0.94285714\n",
      " 0.95238095 0.94285714 0.94285714 0.37142857 0.37142857 0.37142857]\n",
      "  warnings.warn(\n",
      "C:\\Users\\fross\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline\n",
    "pipe = Pipeline([(\"classifier\", RandomForestClassifier())])\n",
    "\n",
    "# Create dictionary with candidate learning algorithms and their hyperparameters\n",
    "grid_param = [\n",
    "                {\"classifier\": [LogisticRegression()],\n",
    "                 \"classifier__penalty\": ['l2', 'l1'],\n",
    "                 \"classifier__C\": np.logspace(0, 4, 10)\n",
    "                 },\n",
    "                {\"classifier\": [LogisticRegression()],\n",
    "                 \"classifier__penalty\": ['l2'],\n",
    "                 \"classifier__C\": np.logspace(0, 4, 10),\n",
    "                 \"classifier__solver\":['newton-cg', 'saga', 'sag', 'liblinear'] ##This solvers don't allow L1 penalty\n",
    "                 },\n",
    "                {\"classifier\": [RandomForestClassifier()],\n",
    "                 \"classifier__n_estimators\": [10, 100, 1000],\n",
    "                 \"classifier__max_depth\":[5, 8, 15, 25, 30, None],\n",
    "                 \"classifier__min_samples_leaf\":[1, 2, 5, 10, 15, 100],\n",
    "                 \"classifier__max_leaf_nodes\": [2, 5, 10]}]\n",
    "\n",
    "# create a gridsearch of the pipeline, the fit the best model\n",
    "gridsearch = GridSearchCV(pipe, grid_param, cv=5, verbose=0, n_jobs=-1) # Fit grid search\n",
    "best_model = gridsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61177e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('classifier', LogisticRegression(solver='saga'))])\n",
      "The mean accuracy of the model is: 0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "print(best_model.best_estimator_)\n",
    "print(\"The mean accuracy of the model is:\",best_model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8fbe5e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(solver='saga'),\n",
       " 'classifier__C': 1.0,\n",
       " 'classifier__penalty': 'l2',\n",
       " 'classifier__solver': 'saga'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9d3247",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
